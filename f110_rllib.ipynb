{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1bd4eb",
   "metadata": {},
   "source": [
    "# F1tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b781558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f07c65",
   "metadata": {},
   "source": [
    "## Environment playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e382dbcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# racecar_env = gym.make(\n",
    "#     'f110_gym:f110-v0',\n",
    "#     map='./f1tenth_gym/gym/f110_gym/envs/maps/vegas',\n",
    "#     map_ext='.png'\n",
    "# )\n",
    "\n",
    "racecar_env = gym.make(\n",
    "    'f110_gym:f110-v0',\n",
    "    map='./f1tenth_gym/examples/example_map',\n",
    "    map_ext='.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acba6632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ego_idx': 0,\n",
       " 'scans': [array([29.98576175, 30.01263728, 29.99129338, ..., 29.99864406,\n",
       "         29.9889291 , 30.01278365]),\n",
       "  array([29.98576175, 30.01263728, 29.99129338, ..., 29.99864406,\n",
       "         29.9889291 , 30.01278365])],\n",
       " 'poses_x': [0.0, 2.0],\n",
       " 'poses_y': [0.0, 0.0],\n",
       " 'poses_theta': [0.0, 0.0],\n",
       " 'linear_vels_x': [0.0, 0.0],\n",
       " 'linear_vels_y': [0.0, 0.0],\n",
       " 'ang_vels_z': [0.0, 0.0],\n",
       " 'collisions': array([0., 0.]),\n",
       " 'lap_times': array([0.01, 0.01]),\n",
       " 'lap_counts': array([0., 0.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, step_reward, done, info = racecar_env.reset(\n",
    "    poses=np.array([[0., 0., 0.], # pose of ego\n",
    "             [2., 0., 0.]])  # pose of 2nd agent\n",
    ") \n",
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df1290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.concatenate([\n",
    "    obs['scans'][0],\n",
    "    np.array(obs['linear_vels_x'][:1]),\n",
    "    np.array(obs['linear_vels_y'][:1]),\n",
    "])\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54349ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0596855 ,  0.44670051],\n",
       "       [-0.05675966,  1.8354974 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeds = np.random.rand(2, 1)*2\n",
    "pi_4 = 3.1415/8\n",
    "pi_2 = 3.1415/4\n",
    "angles = np.random.rand(2, 1)*pi_2-pi_4\n",
    "actions = np.concatenate([angles, speeds], axis=1)\n",
    "\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133a6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## action consists of ndarray(num_agent, 2) 0: steering angle 1: velocity\n",
    "## the reward function is only for the first agent\n",
    "\n",
    "import time\n",
    "import gym \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "racecar_env = gym.make(\n",
    "    'f110_gym:f110-v0',\n",
    "    map='./f1tenth_gym/examples/example_map',\n",
    "    map_ext='.png',\n",
    "    num_agents=1\n",
    ")\n",
    "steps = 0\n",
    "\n",
    "obs, step_reward, done, info = racecar_env.reset(\n",
    "    poses=np.array([[0., 0., 1.5]]) \n",
    ") \n",
    "\n",
    "rewards = []\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    speeds = np.random.rand(2, 1)*20\n",
    "    pi_4 = 3.1415/8\n",
    "    pi_2 = 3.1415/4\n",
    "    speeds[1][0] = 0.1\n",
    "    angles = np.random.rand(2, 1)*pi_2-pi_4\n",
    "    actions = np.concatenate([angles, speeds], axis=1)\n",
    "\n",
    "    obs, step_reward, done, info = racecar_env.step(actions)\n",
    "    rewards.append(step_reward)\n",
    "    \n",
    "    racecar_env.render()\n",
    "    steps += 1\n",
    "    \n",
    "    if steps > 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1c0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa25f6c8460>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60a5e8",
   "metadata": {},
   "source": [
    "## Define environment wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db0c21",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437acb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import yaml\n",
    "import gym\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from pyglet.gl import GL_POINTS\n",
    "\n",
    "\n",
    "# @njit(fastmath=False, cache=True)\n",
    "def nearest_point_on_trajectory(point, trajectory):\n",
    "    \"\"\"\n",
    "    Return the nearest point along the given piecewise linear trajectory.\n",
    "\n",
    "    Same as nearest_point_on_line_segment, but vectorized. This method is quite fast, time constraints should\n",
    "    not be an issue so long as trajectories are not insanely long.\n",
    "\n",
    "        Order of magnitude: trajectory length: 1000 --> 0.0002 second computation (5000fps)\n",
    "\n",
    "    point: size 2 numpy array\n",
    "    trajectory: Nx2 matrix of (x,y) trajectory waypoints\n",
    "        - these must be unique. If they are not unique, a divide by 0 error will destroy the world\n",
    "    \"\"\"\n",
    "    diffs = trajectory[1:,:] - trajectory[:-1,:]\n",
    "    l2s   = diffs[:,0]**2 + diffs[:,1]**2\n",
    "    # this is equivalent to the elementwise dot product\n",
    "    # dots = np.sum((point - trajectory[:-1,:]) * diffs[:,:], axis=1)\n",
    "    dots = np.empty((trajectory.shape[0]-1, ))\n",
    "    for i in range(dots.shape[0]):\n",
    "        dots[i] = np.dot((point - trajectory[i, :]), diffs[i, :])\n",
    "    t = dots / l2s\n",
    "    t[t<0.0] = 0.0\n",
    "    t[t>1.0] = 1.0\n",
    "    # t = np.clip(dots / l2s, 0.0, 1.0)\n",
    "    projections = trajectory[:-1,:] + (t*diffs.T).T\n",
    "    # dists = np.linalg.norm(point - projections, axis=1)\n",
    "    dists = np.empty((projections.shape[0],))\n",
    "    for i in range(dists.shape[0]):\n",
    "        temp = point - projections[i]\n",
    "        dists[i] = np.sqrt(np.sum(temp*temp))\n",
    "    min_dist_segment = np.argmin(dists)\n",
    "    return projections[min_dist_segment], dists[min_dist_segment], t[min_dist_segment], min_dist_segment\n",
    "\n",
    "# @njit(fastmath=False, cache=True)\n",
    "def first_point_on_trajectory_intersecting_circle(point, radius, trajectory, t=0.0, wrap=False):\n",
    "    \"\"\"\n",
    "    starts at beginning of trajectory, and find the first point one radius away from the given point along the trajectory.\n",
    "\n",
    "    Assumes that the first segment passes within a single radius of the point\n",
    "\n",
    "    http://codereview.stackexchange.com/questions/86421/line-segment-to-circle-collision-algorithm\n",
    "    \"\"\"\n",
    "    start_i = int(t)\n",
    "    start_t = t % 1.0\n",
    "    first_t = None\n",
    "    first_i = None\n",
    "    first_p = None\n",
    "    trajectory = np.ascontiguousarray(trajectory)\n",
    "    for i in range(start_i, trajectory.shape[0]-1):\n",
    "        start = trajectory[i,:]\n",
    "        end = trajectory[i+1,:]+1e-6\n",
    "        V = np.ascontiguousarray(end - start)\n",
    "\n",
    "        a = np.dot(V,V)\n",
    "        b = 2.0*np.dot(V, start - point)\n",
    "        c = np.dot(start, start) + np.dot(point,point) - 2.0*np.dot(start, point) - radius*radius\n",
    "        discriminant = b*b-4*a*c\n",
    "\n",
    "        if discriminant < 0:\n",
    "            continue\n",
    "        #   print \"NO INTERSECTION\"\n",
    "        # else:\n",
    "        # if discriminant >= 0.0:\n",
    "        discriminant = np.sqrt(discriminant)\n",
    "        t1 = (-b - discriminant) / (2.0*a)\n",
    "        t2 = (-b + discriminant) / (2.0*a)\n",
    "        if i == start_i:\n",
    "            if t1 >= 0.0 and t1 <= 1.0 and t1 >= start_t:\n",
    "                first_t = t1\n",
    "                first_i = i\n",
    "                first_p = start + t1 * V\n",
    "                break\n",
    "            if t2 >= 0.0 and t2 <= 1.0 and t2 >= start_t:\n",
    "                first_t = t2\n",
    "                first_i = i\n",
    "                first_p = start + t2 * V\n",
    "                break\n",
    "        elif t1 >= 0.0 and t1 <= 1.0:\n",
    "            first_t = t1\n",
    "            first_i = i\n",
    "            first_p = start + t1 * V\n",
    "            break\n",
    "        elif t2 >= 0.0 and t2 <= 1.0:\n",
    "            first_t = t2\n",
    "            first_i = i\n",
    "            first_p = start + t2 * V\n",
    "            break\n",
    "    # wrap around to the beginning of the trajectory if no intersection is found1\n",
    "    if wrap and first_p is None:\n",
    "        for i in range(-1, start_i):\n",
    "            start = trajectory[i % trajectory.shape[0],:]\n",
    "            end = trajectory[(i+1) % trajectory.shape[0],:]+1e-6\n",
    "            V = end - start\n",
    "\n",
    "            a = np.dot(V,V)\n",
    "            b = 2.0*np.dot(V, start - point)\n",
    "            c = np.dot(start, start) + np.dot(point,point) - 2.0*np.dot(start, point) - radius*radius\n",
    "            discriminant = b*b-4*a*c\n",
    "\n",
    "            if discriminant < 0:\n",
    "                continue\n",
    "            discriminant = np.sqrt(discriminant)\n",
    "            t1 = (-b - discriminant) / (2.0*a)\n",
    "            t2 = (-b + discriminant) / (2.0*a)\n",
    "            if t1 >= 0.0 and t1 <= 1.0:\n",
    "                first_t = t1\n",
    "                first_i = i\n",
    "                first_p = start + t1 * V\n",
    "                break\n",
    "            elif t2 >= 0.0 and t2 <= 1.0:\n",
    "                first_t = t2\n",
    "                first_i = i\n",
    "                first_p = start + t2 * V\n",
    "                break\n",
    "\n",
    "    return first_p, first_i, first_t\n",
    "\n",
    "# @njit(fastmath=False, cache=True)\n",
    "def get_actuation(pose_theta, lookahead_point, position, lookahead_distance, wheelbase):\n",
    "    \"\"\"\n",
    "    Returns actuation\n",
    "    \"\"\"\n",
    "    waypoint_y = np.dot(np.array([np.sin(-pose_theta), np.cos(-pose_theta)]), lookahead_point[0:2]-position)\n",
    "    speed = lookahead_point[2]\n",
    "    if np.abs(waypoint_y) < 1e-6:\n",
    "        return speed, 0.\n",
    "    radius = 1/(2.0*waypoint_y/lookahead_distance**2)\n",
    "    steering_angle = np.arctan(wheelbase/radius)\n",
    "    return speed, steering_angle\n",
    "\n",
    "class PurePursuitPlanner:\n",
    "    \"\"\"\n",
    "    Example Planner\n",
    "    \"\"\"\n",
    "    def __init__(self, conf, wb):\n",
    "        self.wheelbase = wb\n",
    "        self.conf = conf\n",
    "        self.load_waypoints(conf)\n",
    "        self.max_reacquire = 20.\n",
    "\n",
    "        self.drawn_waypoints = []\n",
    "\n",
    "    def load_waypoints(self, conf):\n",
    "        \"\"\"\n",
    "        loads waypoints\n",
    "        \"\"\"\n",
    "        self.waypoints = np.loadtxt(conf.wpt_path, delimiter=conf.wpt_delim, skiprows=conf.wpt_rowskip)\n",
    "\n",
    "    def render_waypoints(self, e):\n",
    "        \"\"\"\n",
    "        update waypoints being drawn by EnvRenderer\n",
    "        \"\"\"\n",
    "\n",
    "        #points = self.waypoints\n",
    "\n",
    "        points = np.vstack((self.waypoints[:, self.conf.wpt_xind], self.waypoints[:, self.conf.wpt_yind])).T\n",
    "        \n",
    "        scaled_points = 50.*points\n",
    "\n",
    "        for i in range(points.shape[0]):\n",
    "            if len(self.drawn_waypoints) < points.shape[0]:\n",
    "                b = e.batch.add(1, GL_POINTS, None, ('v3f/stream', [scaled_points[i, 0], scaled_points[i, 1], 0.]),\n",
    "                                ('c3B/stream', [183, 193, 222]))\n",
    "                self.drawn_waypoints.append(b)\n",
    "            else:\n",
    "                self.drawn_waypoints[i].vertices = [scaled_points[i, 0], scaled_points[i, 1], 0.]\n",
    "        \n",
    "    def _get_current_waypoint(self, waypoints, lookahead_distance, position, theta):\n",
    "        \"\"\"\n",
    "        gets the current waypoint to follow\n",
    "        \"\"\"\n",
    "        wpts = np.vstack((self.waypoints[:, self.conf.wpt_xind], self.waypoints[:, self.conf.wpt_yind])).T\n",
    "        nearest_point, nearest_dist, t, i = nearest_point_on_trajectory(position, wpts)\n",
    "        if nearest_dist < lookahead_distance:\n",
    "            lookahead_point, i2, t2 = first_point_on_trajectory_intersecting_circle(position, lookahead_distance, wpts, i+t, wrap=True)\n",
    "            if i2 == None:\n",
    "                return None\n",
    "            current_waypoint = np.empty((3, ))\n",
    "            # x, y\n",
    "            current_waypoint[0:2] = wpts[i2, :]\n",
    "            # speed\n",
    "            current_waypoint[2] = waypoints[i, self.conf.wpt_vind]\n",
    "            return current_waypoint\n",
    "        elif nearest_dist < self.max_reacquire:\n",
    "            return np.append(wpts[i, :], waypoints[i, self.conf.wpt_vind])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def plan(self, pose_x, pose_y, pose_theta, lookahead_distance, vgain):\n",
    "        \"\"\"\n",
    "        gives actuation given observation\n",
    "        \"\"\"\n",
    "        position = np.array([pose_x, pose_y])\n",
    "        lookahead_point = self._get_current_waypoint(self.waypoints, lookahead_distance, position, pose_theta)\n",
    "\n",
    "        if lookahead_point is None:\n",
    "            return 4.0, 0.0\n",
    "\n",
    "        speed, steering_angle = get_actuation(pose_theta, lookahead_point, position, lookahead_distance, self.wheelbase)\n",
    "        speed = vgain * speed\n",
    "\n",
    "        return speed, steering_angle\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    main entry point\n",
    "    \"\"\"\n",
    "\n",
    "    work = {'mass': 3.463388126201571, 'lf': 0.15597534362552312, 'tlad': 1.82461887897713965, 'vgain': 0.90338203837889}\n",
    "    \n",
    "    with open('./f1tenth_gym/examples/config_example_map.yaml') as file:\n",
    "        conf_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    conf = Namespace(**conf_dict)\n",
    "\n",
    "    planner = PurePursuitPlanner(conf, 0.17145+0.15875)\n",
    "\n",
    "    def render_callback(env_renderer):\n",
    "        # custom extra drawing function\n",
    "\n",
    "        e = env_renderer\n",
    "\n",
    "        # update camera to follow car\n",
    "        x = e.cars[0].vertices[::2]\n",
    "        y = e.cars[0].vertices[1::2]\n",
    "        top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "        e.score_label.x = left\n",
    "        e.score_label.y = top - 700\n",
    "        e.left = left - 800\n",
    "        e.right = right + 800\n",
    "        e.top = top + 800\n",
    "        e.bottom = bottom - 800\n",
    "\n",
    "        planner.render_waypoints(env_renderer)\n",
    "\n",
    "    env = gym.make('f110_gym:f110-v0', map=conf.map_path, map_ext=conf.map_ext, num_agents=1)\n",
    "    env.add_render_callback(render_callback)\n",
    "    \n",
    "    obs, step_reward, done, info = env.reset(np.array([[conf.sx, conf.sy, conf.stheta]]))\n",
    "    env.render()\n",
    "\n",
    "    laptime = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    while not done:\n",
    "        speed, steer = planner.plan(obs['poses_x'][0], obs['poses_y'][0], obs['poses_theta'][0], work['tlad'], work['vgain'])\n",
    "        obs, step_reward, done, info = env.step(np.array([[steer, speed]]))\n",
    "        laptime += step_reward\n",
    "        env.render(mode='human')\n",
    "        \n",
    "    print('Sim elapsed time:', laptime, 'Real elapsed time:', time.time()-start)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d4767",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### waypoint handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac2f85b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "import gym\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "\n",
    "# @njit(fastmath=False, cache=True)\n",
    "def nearest_point_on_trajectory(point, trajectory):\n",
    "    \"\"\"\n",
    "    Return the nearest point along the given piecewise linear trajectory.\n",
    "\n",
    "    Same as nearest_point_on_line_segment, but vectorized. This method is quite fast, time constraints should\n",
    "    not be an issue so long as trajectories are not insanely long.\n",
    "\n",
    "        Order of magnitude: trajectory length: 1000 --> 0.0002 second computation (5000fps)\n",
    "\n",
    "    point: size 2 numpy array\n",
    "    trajectory: Nx2 matrix of (x,y) trajectory waypoints\n",
    "        - these must be unique. If they are not unique, a divide by 0 error will destroy the world\n",
    "    \"\"\"\n",
    "    diffs = trajectory[1:,:] - trajectory[:-1,:]\n",
    "    l2s   = diffs[:,0]**2 + diffs[:,1]**2\n",
    "    # this is equivalent to the elementwise dot product\n",
    "    # dots = np.sum((point - trajectory[:-1,:]) * diffs[:,:], axis=1)\n",
    "    dots = np.empty((trajectory.shape[0]-1, ))\n",
    "    for i in range(dots.shape[0]):\n",
    "        dots[i] = np.dot((point - trajectory[i, :]), diffs[i, :])\n",
    "    t = dots / l2s\n",
    "    t[t<0.0] = 0.0\n",
    "    t[t>1.0] = 1.0\n",
    "    # t = np.clip(dots / l2s, 0.0, 1.0)\n",
    "    projections = trajectory[:-1,:] + (t*diffs.T).T\n",
    "    # dists = np.linalg.norm(point - projections, axis=1)\n",
    "    dists = np.empty((projections.shape[0],))\n",
    "    for i in range(dists.shape[0]):\n",
    "        temp = point - projections[i]\n",
    "        dists[i] = np.sqrt(np.sum(temp*temp))\n",
    "    min_dist_segment = np.argmin(dists)\n",
    "    return projections[min_dist_segment], dists[min_dist_segment], t[min_dist_segment], min_dist_segment\n",
    "\n",
    "# @njit(fastmath=False, cache=True)\n",
    "def first_point_on_trajectory_intersecting_circle(point, radius, trajectory, t=0.0, wrap=False):\n",
    "    \"\"\"\n",
    "    starts at beginning of trajectory, and find the first point one radius away from the given point along the trajectory.\n",
    "\n",
    "    Assumes that the first segment passes within a single radius of the point\n",
    "\n",
    "    http://codereview.stackexchange.com/questions/86421/line-segment-to-circle-collision-algorithm\n",
    "    \"\"\"\n",
    "    start_i = int(t)\n",
    "    start_t = t % 1.0\n",
    "    first_t = None\n",
    "    first_i = None\n",
    "    first_p = None\n",
    "    trajectory = np.ascontiguousarray(trajectory)\n",
    "    for i in range(start_i, trajectory.shape[0]-1):\n",
    "        start = trajectory[i,:]\n",
    "        end = trajectory[i+1,:]+1e-6\n",
    "        V = np.ascontiguousarray(end - start)\n",
    "\n",
    "        a = np.dot(V,V)\n",
    "        b = 2.0*np.dot(V, start - point)\n",
    "        c = np.dot(start, start) + np.dot(point,point) - 2.0*np.dot(start, point) - radius*radius\n",
    "        discriminant = b*b-4*a*c\n",
    "\n",
    "        if discriminant < 0:\n",
    "            continue\n",
    "        #   print \"NO INTERSECTION\"\n",
    "        # else:\n",
    "        # if discriminant >= 0.0:\n",
    "        discriminant = np.sqrt(discriminant)\n",
    "        t1 = (-b - discriminant) / (2.0*a)\n",
    "        t2 = (-b + discriminant) / (2.0*a)\n",
    "        if i == start_i:\n",
    "            if t1 >= 0.0 and t1 <= 1.0 and t1 >= start_t:\n",
    "                first_t = t1\n",
    "                first_i = i\n",
    "                first_p = start + t1 * V\n",
    "                break\n",
    "            if t2 >= 0.0 and t2 <= 1.0 and t2 >= start_t:\n",
    "                first_t = t2\n",
    "                first_i = i\n",
    "                first_p = start + t2 * V\n",
    "                break\n",
    "        elif t1 >= 0.0 and t1 <= 1.0:\n",
    "            first_t = t1\n",
    "            first_i = i\n",
    "            first_p = start + t1 * V\n",
    "            break\n",
    "        elif t2 >= 0.0 and t2 <= 1.0:\n",
    "            first_t = t2\n",
    "            first_i = i\n",
    "            first_p = start + t2 * V\n",
    "            break\n",
    "    # wrap around to the beginning of the trajectory if no intersection is found1\n",
    "    if wrap and first_p is None:\n",
    "        for i in range(-1, start_i):\n",
    "            start = trajectory[i % trajectory.shape[0],:]\n",
    "            end = trajectory[(i+1) % trajectory.shape[0],:]+1e-6\n",
    "            V = end - start\n",
    "\n",
    "            a = np.dot(V,V)\n",
    "            b = 2.0*np.dot(V, start - point)\n",
    "            c = np.dot(start, start) + np.dot(point,point) - 2.0*np.dot(start, point) - radius*radius\n",
    "            discriminant = b*b-4*a*c\n",
    "\n",
    "            if discriminant < 0:\n",
    "                continue\n",
    "            discriminant = np.sqrt(discriminant)\n",
    "            t1 = (-b - discriminant) / (2.0*a)\n",
    "            t2 = (-b + discriminant) / (2.0*a)\n",
    "            if t1 >= 0.0 and t1 <= 1.0:\n",
    "                first_t = t1\n",
    "                first_i = i\n",
    "                first_p = start + t1 * V\n",
    "                break\n",
    "            elif t2 >= 0.0 and t2 <= 1.0:\n",
    "                first_t = t2\n",
    "                first_i = i\n",
    "                first_p = start + t2 * V\n",
    "                break\n",
    "\n",
    "    return first_p, first_i, first_t\n",
    "    \n",
    "    \n",
    "CAPTURE_TIME = 100\n",
    "class F110Env(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(2,))\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(217,), dtype=np.float32)\n",
    "\n",
    "        \n",
    "        work = {'mass': 3.463388126201571, 'lf': 0.15597534362552312, 'tlad': 1.82461887897713965, 'vgain': 0.90338203837889}\n",
    "\n",
    "        with open('./f1tenth_gym/examples/config_example_map.yaml') as file:\n",
    "            conf_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        conf = Namespace(**conf_dict)\n",
    "        self.conf = conf\n",
    "        self.load_waypoints(conf)\n",
    "        self.max_reacquire = 20.\n",
    "\n",
    "        def render_callback(env_renderer):\n",
    "            # custom extra drawing function\n",
    "\n",
    "            e = env_renderer\n",
    "\n",
    "            # update camera to follow car\n",
    "            x = e.cars[0].vertices[::2]\n",
    "            y = e.cars[0].vertices[1::2]\n",
    "            top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "            e.score_label.x = left\n",
    "            e.score_label.y = top - 700\n",
    "            e.left = left - 800\n",
    "            e.right = right + 800\n",
    "            e.top = top + 800\n",
    "            e.bottom = bottom - 800\n",
    "\n",
    "\n",
    "        self.env = gym.make('f110_gym:f110-v0', map=conf.map_path, map_ext=conf.map_ext, num_agents=1)\n",
    "        self.env.add_render_callback(render_callback)\n",
    "        self.prev_capture_coord = None\n",
    "        self.reset()\n",
    "        \n",
    "    def load_waypoints(self, conf):\n",
    "        \"\"\"\n",
    "        loads waypoints\n",
    "        \"\"\"\n",
    "        self.waypoints = np.loadtxt(conf.wpt_path, delimiter=conf.wpt_delim, skiprows=conf.wpt_rowskip)\n",
    "\n",
    "        \n",
    "    def _get_current_waypoint(self, waypoints, lookahead_distance, position, theta):\n",
    "        \"\"\"\n",
    "        gets the current waypoint to follow\n",
    "        \"\"\"\n",
    "        wpts = np.vstack((self.waypoints[:, self.conf.wpt_xind], self.waypoints[:, self.conf.wpt_yind])).T\n",
    "        nearest_point, nearest_dist, t, i = nearest_point_on_trajectory(position, wpts)\n",
    "        if nearest_dist < lookahead_distance:\n",
    "            lookahead_point, i2, t2 = first_point_on_trajectory_intersecting_circle(position, lookahead_distance, wpts, i+t, wrap=True)\n",
    "            if i2 == None:\n",
    "                return None\n",
    "            current_waypoint = np.empty((3, ))\n",
    "            # x, y\n",
    "            current_waypoint[0:2] = wpts[i2, :]\n",
    "            # speed\n",
    "            current_waypoint[2] = waypoints[i, self.conf.wpt_vind]\n",
    "            return current_waypoint\n",
    "        elif nearest_dist < self.max_reacquire:\n",
    "            return np.append(wpts[i, :], waypoints[i, self.conf.wpt_vind])\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def reset(self):\n",
    "        obs, step_reward, done, info = self.env.reset(np.array([[self.conf.sx, self.conf.sy, self.conf.stheta]]))\n",
    "        self.prev_capture_coord = [obs['poses_x'][0], obs['poses_y'][0]]\n",
    "        self.time_to_capture = CAPTURE_TIME\n",
    "        self.init_x = 0\n",
    "        return self.to_vector_state(obs)\n",
    "    \n",
    "    def to_vector_state(self, obs):\n",
    "\n",
    "        scanner = np.zeros(1080//5,)\n",
    "        for i in range(1080//5):\n",
    "            scanner[i] = np.clip(np.mean(obs['scans'][0][i*5: i*5+5]), 0, 10)\n",
    "\n",
    "        scanner /= 10\n",
    "        state = np.concatenate([\n",
    "            scanner,\n",
    "            np.array(obs['linear_vels_x'][:1])/5,\n",
    "        ])\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "\n",
    "        action[0] = action[0]*np.pi/4\n",
    "        action[1] = action[1]*2.5 + 2.5\n",
    "        action = action.reshape(1, 2)\n",
    "        action = np.repeat(action, repeats=2, axis=0)\n",
    "        action[1][1] = 0\n",
    "        # print(action)\n",
    "        \n",
    "\n",
    "        obs, step_reward, done, info = self.env.step(action)\n",
    "        \n",
    "        pose_x = obs['poses_x'][0]\n",
    "        pose_y = obs['poses_y'][0]\n",
    "        \n",
    "        position = np.array([pose_x, pose_y])\n",
    "        lookahead_point = self._get_current_waypoint(self.waypoints, 1.8, position, 0.9033)\n",
    "        \n",
    "        print(position, lookahead_point)\n",
    "        \n",
    "        reward = 0\n",
    "        if obs['collisions'][0] == 1.0:\n",
    "            reward = -10\n",
    "        \n",
    "\n",
    "        next_state = self.to_vector_state(obs)\n",
    "        reward += (step_reward + obs['linear_vels_x'][0]*0.01)\n",
    "\n",
    "        self.time_to_capture -= 1\n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b6255",
   "metadata": {},
   "source": [
    "### checkpoint handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1065254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "import gym\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "\n",
    "    \n",
    "class F110Env(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(2,))\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(217,), dtype=np.float32)\n",
    "        self.min_cp_dist = 1.0\n",
    "        self.cp_reward = 5.0\n",
    "\n",
    "        with open('./f1tenth_gym/examples/config_example_map.yaml') as file:\n",
    "            conf_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        conf = Namespace(**conf_dict)\n",
    "        self.conf = conf\n",
    "        wps = np.loadtxt(conf.wpt_path, delimiter=conf.wpt_delim, skiprows=conf.wpt_rowskip)[:, 1:3]\n",
    "        idxs = [i%10 == 0 for i in range(len(wps))]\n",
    "        self.checkpoints = wps[idxs]\n",
    "\n",
    "        def render_callback(env_renderer):\n",
    "            # custom extra drawing function\n",
    "\n",
    "            e = env_renderer\n",
    "\n",
    "            # update camera to follow car\n",
    "            x = e.cars[0].vertices[::2]\n",
    "            y = e.cars[0].vertices[1::2]\n",
    "            top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "            e.score_label.x = left\n",
    "            e.score_label.y = top - 700\n",
    "            e.left = left - 800\n",
    "            e.right = right + 800\n",
    "            e.top = top + 800\n",
    "            e.bottom = bottom - 800\n",
    "\n",
    "\n",
    "        self.env = gym.make('f110_gym:f110-v0', map=conf.map_path, map_ext=conf.map_ext, num_agents=1)\n",
    "        self.env.add_render_callback(render_callback)\n",
    "        self.prev_capture_coord = None\n",
    "        self.reset()\n",
    "        \n",
    "  \n",
    "    def reset(self):\n",
    "        obs, step_reward, done, info = self.env.reset(np.array([[self.conf.sx, self.conf.sy, self.conf.stheta]]))\n",
    "        self.next_cp_idx = 0\n",
    "        \n",
    "        return self.to_vector_state(obs)\n",
    "    \n",
    "    def to_vector_state(self, obs):\n",
    "\n",
    "        scanner = np.zeros(1080//5,)\n",
    "        for i in range(1080//5):\n",
    "            scanner[i] = np.clip(np.mean(obs['scans'][0][i*5: i*5+5]), 0, 10)\n",
    "\n",
    "        scanner /= 10\n",
    "        state = np.concatenate([\n",
    "            scanner,\n",
    "            np.array(obs['linear_vels_x'][:1])/5,\n",
    "        ])\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def checkpoint(self, position):\n",
    "        dist = np.linalg.norm(position - self.checkpoints[self.next_cp_idx])\n",
    "        reward = 0\n",
    "        if dist < self.min_cp_dist:\n",
    "            reward = self.cp_reward\n",
    "            self.next_cp_idx = (self.next_cp_idx + 1)%len(self.checkpointsk)\n",
    "        return reward\n",
    "        \n",
    "    def step(self, action):\n",
    "\n",
    "        action[0] = action[0]*np.pi/4\n",
    "        action[1] = action[1]*2.5 + 2.5\n",
    "        action = action.reshape(1, 2)\n",
    "        action = np.repeat(action, repeats=2, axis=0)\n",
    "        action[1][1] = 0\n",
    "        # print(action)\n",
    "        \n",
    "\n",
    "        obs, step_reward, done, info = self.env.step(action)\n",
    "        \n",
    "        pose_x = obs['poses_x'][0]\n",
    "        pose_y = obs['poses_y'][0]\n",
    "        \n",
    "        position = np.array([pose_x, pose_y])\n",
    "        \n",
    "        \n",
    "        reward = 0\n",
    "        if obs['collisions'][0] == 1.0:\n",
    "            reward = -10\n",
    "        \n",
    "        cp_reward = self.checkpoint(position)\n",
    "        \n",
    "        next_state = self.to_vector_state(obs)\n",
    "        reward += (cp_reward + obs['linear_vels_x'][0]*0.01)\n",
    "\n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a704892",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Env simple wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf8e2c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CAPTURE_TIME = 100\n",
    "class F110Env(gym.Env):\n",
    "    def __init__(self, env_config):\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(2,))\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(217,), dtype=np.float32)\n",
    "        \n",
    "        self.env = gym.make(\n",
    "            'f110_gym:f110-v0',\n",
    "            map='./f1tenth_gym/examples/example_map',\n",
    "            map_ext='.png'\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "        self.prev_capture_coord = None\n",
    "        \n",
    "    def reset(self):\n",
    "        obs, step_reward, done, info = self.env.reset(\n",
    "            poses=np.array([[0., 0., 0.], \n",
    "                     [-1., -1., 0.]]) \n",
    "        )\n",
    "        self.prev_capture_coord = [obs['poses_x'][0], obs['poses_y'][0]]\n",
    "        self.time_to_capture = CAPTURE_TIME\n",
    "        self.init_x = 0\n",
    "        return self.to_vector_state(obs)\n",
    "    \n",
    "    def to_vector_state(self, obs):\n",
    "\n",
    "        scanner = np.zeros(1080//5,)\n",
    "        for i in range(1080//5):\n",
    "            scanner[i] = np.clip(np.mean(obs['scans'][0][i*5: i*5+5]), 0, 10)\n",
    "\n",
    "        scanner /= 10\n",
    "        state = np.concatenate([\n",
    "            scanner,\n",
    "            np.array(obs['linear_vels_x'][:1])/5,\n",
    "        ])\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        action[0] = action[0]*np.pi/4\n",
    "        action[1] = action[1]*2.5 + 2.5\n",
    "        action = action.reshape(1, 2)\n",
    "        action = np.repeat(action, repeats=2, axis=0)\n",
    "        action[1][1] = 0\n",
    "        # print(action)\n",
    "        obs, step_reward, done, info = self.env.step(action)\n",
    "        reward = 0\n",
    "        if obs['collisions'][0] == 1.0:\n",
    "            reward = -10\n",
    "        \n",
    "        moving_forward_rew = 0\n",
    "\n",
    "        if self.time_to_capture == 0:\n",
    "            current_coord = [obs['poses_x'][0], obs['poses_y'][0]]\n",
    "            dist = abs(current_coord[0] - self.prev_capture_coord[0]) + abs(current_coord[1] - self.prev_capture_coord[1])\n",
    "            # print(f\"prev coord:{self.prev_capture_coord}, current_coord:{current_coord}, dist:{dist}\")\n",
    "            \n",
    "            self.prev_capture_coord = current_coord\n",
    "            if dist < 2:\n",
    "                # print(\"Neg reward\")\n",
    "                moving_forward_rew = -10\n",
    "\n",
    "            self.time_to_capture = CAPTURE_TIME + 1\n",
    "\n",
    "        next_state = self.to_vector_state(obs)\n",
    "        # ang_vel = obs['ang_vels_z'][0]\n",
    "        # print(obs['ang_vels_z'][0]*0.1)\n",
    "        reward += (step_reward + obs['linear_vels_x'][0]*0.01)\n",
    "\n",
    "        self.time_to_capture -= 1\n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3db7ba",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c033b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "env = F110Env({'explore':False})\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = np.array([1.0, 0.0])\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e9da4",
   "metadata": {},
   "source": [
    "# RAY algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1468137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.agents import ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpu_configs = {\n",
    "    \"num_workers\": 30,\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [512, 512, 128],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    \"evaluation_num_workers\": 5,\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": False,\n",
    "    },\n",
    "    \"num_gpus\": 2\n",
    "}\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"num_workers\": 1,\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [512, 512, 128],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "trainer = ppo.PPOTrainer(env=F110Env, config=config)\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    result = trainer.train()\n",
    "    print(f\"episode: {i} reward:{result['episode_reward_mean']}\")\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        cp = trainer.save(\"./rllib_checkpoint\")\n",
    "        print(\"checkpoint saved at\", checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c7ea0126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 16:38:59,610\tWARNING deprecation.py:45 -- DeprecationWarning: `clear_buffer` has been deprecated. Use `Filter.reset_buffer()` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./rllib_checkpoint/checkpoint_000038/checkpoint-38'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save(\"./rllib_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64aa25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:56:46,197\tWARNING trainer.py:2279 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=70740)\u001b[0m 2022-02-17 15:56:50,270\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "2022-02-17 15:56:50,308\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-02-17 15:56:50,308\tWARNING trainer.py:2279 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-02-17 15:56:50,345\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2022-02-17 15:56:50,393\tINFO trainable.py:472 -- Restored on 128.205.218.23 from checkpoint: ./rllib_checkpoint/checkpoint_000090/checkpoint-90\n",
      "2022-02-17 15:56:50,393\tINFO trainable.py:480 -- Current state after restoring: {'_iteration': 90, '_timesteps_total': 360000, '_time_total': 1223.2796750068665, '_episodes_total': 197}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=70741)\u001b[0m 2022-02-17 15:56:54,434\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "ltrainer = ppo.PPOTrainer(env=F110Env, config=config)\n",
    "ltrainer.restore('./rllib_checkpoint/checkpoint_000090/checkpoint-90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e6cdb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "env = F110Env({'explore':False})\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = ltrainer.compute_action(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d6b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
